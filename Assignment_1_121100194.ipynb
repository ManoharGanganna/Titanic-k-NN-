{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 1_121100194.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**DATA LOADING AND DATA PREPROCESSING**"
      ],
      "metadata": {
        "id": "ukgMU-wT9zX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import library and load data\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "from collections import defaultdict #Have used defualtdict to avoid key error of my dictionary when we dont have value.\n",
        "\n",
        "titanic = pd.read_csv(\"https://github.com/andvise/DataAnalyticsDatasets/blob/16ca8de1233c8643bfe85fcd1cd87c9ff2221312/titanic.csv?raw=True\")"
      ],
      "metadata": {
        "id": "c8qURtrwxa7a"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check data types\n",
        "titanic.dtypes\n",
        "\n",
        "titanic.drop(['PassengerId','Name'], axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "JKJ6MFXCQs9I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check missing values in variables\n",
        "titanic.isnull().sum()\n",
        "\n",
        "#Check how many Null values are preengt in Parents/Children Aboard column\n",
        "titanic['Parents/Children Aboard'].isnull().sum()\n",
        "\n",
        "#Replace missing values with 0\n",
        "titanic['Parents/Children Aboard'] = titanic['Parents/Children Aboard'].fillna(0)\n"
      ],
      "metadata": {
        "id": "MU3lNT3yQnq1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We can see that the Parents/Children Aboard column contains 1 nan value.**"
      ],
      "metadata": {
        "id": "u22DRTYroqS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Transform the Sex column into a numerical one\n",
        "titanic['Sex'] = np.where(titanic['Sex'] == 'female', 0, 1)"
      ],
      "metadata": {
        "id": "JH9U0S8mTpFQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Assigning Predicting Variables to X and Target Variable Y\n",
        "x = titanic.iloc[:,1:]\n",
        "y = titanic.iloc[:,:1]\n"
      ],
      "metadata": {
        "id": "mFHA-cHqVDHU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def min_max_scaling(column):\n",
        "\n",
        "    \"\"\" \n",
        "    Method to scale X and Y values\n",
        "\n",
        "    \"\"\"\n",
        "    return(column-column.min())/(column.max() - column.min())\n",
        "\n",
        "#Scaling X and Y values\n",
        "for xcol in x.columns:\n",
        "    x[[xcol]] = min_max_scaling(x[[xcol]])\n",
        "\n",
        "for ycol in y.columns:\n",
        "    y[[ycol]] = min_max_scaling(y[[ycol]])\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "cJfcdLCadjMf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Divide the data into training and testing set with 80% of training data and 20% of testing data\n",
        "\n",
        "X_train = x.sample(frac=0.8, random_state=1)\n",
        "X_test = x.drop(X_train.index)\n",
        "\n",
        "Y_train = y.sample(frac=0.8, random_state=1)\n",
        "Y_test = y.drop(Y_train.index)"
      ],
      "metadata": {
        "id": "HZXKz2B1oeuM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Shape of test and training data\n",
        "x_training_data_shape = X_train.shape\n",
        "x_testing_data_shape = X_test.shape\n",
        "\n",
        "y_training_data_shape = Y_train.shape\n",
        "y_testing_data_shape = Y_test.shape\n",
        "\n",
        "print(\"X_train_shape:\",x_training_data_shape,\"Y_train_shape:\",y_training_data_shape)\n",
        "print(\"X_test_shape:\",x_testing_data_shape,\"Y_test_shape:\",y_testing_data_shape)"
      ],
      "metadata": {
        "id": "l_LSbcT9gAKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "139d4167-3ae0-465b-b277-a9d7a16259a4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_shape: (710, 6) Y_train_shape: (710, 1)\n",
            "X_test_shape: (177, 6) Y_test_shape: (177, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 - k-NN implementation\n"
      ],
      "metadata": {
        "id": "cnIPDFkDRgQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class to implement KNN"
      ],
      "metadata": {
        "id": "3_0_M0tG_EAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KNN:\n",
        "\n",
        "    def __init__(self, k):\n",
        "        \"\"\"\n",
        "        Let k equal the assumed number of classifications.\n",
        "        \n",
        "        \"\"\"\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        This method will fit training data to the model. We also assert that then length\n",
        "        of the training data and targets are the same, otherwise the prediction method will break.\n",
        "        \"\"\"\n",
        "        assert len(X) == len(y)\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        return self\n",
        "\n",
        "    def _distance(self, data1, data2):\n",
        "        \"\"\"\n",
        "        Finding the eucledian distance\n",
        "        \"\"\"\n",
        "        return np.sqrt(sum((data1 - data2)**2))\n",
        "  \n",
        "    def _predict_one(self, test):\n",
        "        \"\"\"\n",
        "        Method that takes the fitted model and runs the X_test data comparing\n",
        "        the Euclidean distances between each point. The values are sorted, and \n",
        "        the highest values are stored to give a prediction on targets for one \n",
        "        instance.\n",
        "        \"\"\"\n",
        "        distances = sorted((self._distance(x, test), y) for x, y in zip(self.X, self.y))\n",
        "        neighbors = distances[:self.k]\n",
        "        neighbours_by_class = defaultdict(list)\n",
        "        for d, c in neighbors:\n",
        "            neighbours_by_class[c].append(d)\n",
        "        return max((sum(val), key) for key, val in neighbours_by_class.items())[1]\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Methods for predicting each instance\n",
        "        \"\"\"\n",
        "        return [self._predict_one(x) for x in X]\n",
        "\n",
        "    def score(self, X, y):\n",
        "        \"\"\"\n",
        "        Method takes the X_test and y_test, runs the data through the predict method.\n",
        "        The number of successful guesses are summed and compared to the total \n",
        "        number in the test data.\n",
        "        \"\"\"\n",
        "        return sum(1 for pred, true in zip(self.predict(X), y) if pred == true) / len(y)"
      ],
      "metadata": {
        "id": "9csM9Gv2Q9Yr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a flatten method to convert my dataframe into lists"
      ],
      "metadata": {
        "id": "5WEB0tyY7Me5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Method to flatten list of lists to a single list\n",
        "def flatten(t):\n",
        "    return [item for sublist in t for item in sublist]"
      ],
      "metadata": {
        "id": "8wkXA6N9vg_J"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of KNN with inputs.\n",
        "\n",
        "Input paramaters \n",
        "X as numpy array,\n",
        "Y as list.\n",
        "\n"
      ],
      "metadata": {
        "id": "vqycKVEd_ltg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate the weighted KNN model with K\n",
        "testing_neighbors_knn = KNN(k=5)\n",
        "\n",
        "# Fit the model to the training data.\n",
        "testing_neighbors_knn.fit(X_train.to_numpy(), flatten(Y_train.values.tolist()))\n",
        "\n",
        "# Run predictions using the test sample data.\n",
        "prediction = testing_neighbors_knn.predict(X_test.to_numpy())\n",
        "\n",
        "# Prediction accuracy.\n",
        "pred_acc_knn = testing_neighbors_knn.score(X_test.to_numpy(),flatten(Y_test.values.tolist()))\n",
        "\n",
        "data = {'y_Actual':   flatten(Y_test.values.tolist()),\n",
        "       'y_Predicted': prediction \n",
        "       }\n",
        "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], \n",
        "                               rownames=['Actual'], colnames=['Predicted'], \n",
        "                               margins = True)\n",
        "\n",
        "print('The accuracy of the model is :', round(pred_acc_knn*100,2),'%')\n",
        "print(\"***************************\")\n",
        "print(\"'Confusion Matrix'\")\n",
        "print(\"***************************\")\n",
        "print(confusion_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjaZJLdwvxLW",
        "outputId": "93001746-fe00-43cf-a38c-5e19d3db8ca7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the model is : 86.44 %\n",
            "***************************\n",
            "'Confusion Matrix'\n",
            "***************************\n",
            "Predicted  0.0  1.0  All\n",
            "Actual                  \n",
            "0.0         96    8  104\n",
            "1.0         16   57   73\n",
            "All        112   65  177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The confusion matrix shows that model predicted correctly for 96 people for the survival 0 (i.e people who did not survive) and 57 for the survival 1(i.e people who survived).\n",
        "\n",
        "It also shows that it wrongly predicted as 1 for 0 (i.e predicted as they survived but even though they did not) for 8.\n",
        "\n",
        "It also shows that it wrongly predicted as 0 for 1 (i.e predicted as they did not survive but even though they did) for 16.\n"
      ],
      "metadata": {
        "id": "JAI9NCLlR5k3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3 - Hyperparameters search \n"
      ],
      "metadata": {
        "id": "VTcjCv_lSB3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K=[1, 3, 5, 7, 9, 11]\n",
        "\n",
        "for i in K :\n",
        "  #Instantiate the weighted KNN model with K\n",
        "  testing_neighbors_knn = KNN(k=i)\n",
        "\n",
        "  # Fit the model to the training data.\n",
        "  testing_neighbors_knn.fit(X_train.to_numpy(), flatten(Y_train.values.tolist()))\n",
        "\n",
        "  # Run predictions using the test sample data.\n",
        "  prediction = testing_neighbors_knn.predict(X_test.to_numpy())\n",
        "\n",
        "  # Prediction accuracy.\n",
        "  pred_acc_knn = testing_neighbors_knn.score(X_test.to_numpy(),flatten(Y_test.to_numpy()))\n",
        "\n",
        "  print(\"The accuracy of the model is %.2f%s for K = %d\" % (round(pred_acc_knn*100,2),'%', i))\n",
        "\n"
      ],
      "metadata": {
        "id": "iQybOEzYSYdq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bacd6138-597f-458e-cb12-9ef58e26581b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the model is 81.92% for K = 1\n",
            "The accuracy of the model is 83.05% for K = 3\n",
            "The accuracy of the model is 86.44% for K = 5\n",
            "The accuracy of the model is 82.49% for K = 7\n",
            "The accuracy of the model is 79.10% for K = 9\n",
            "The accuracy of the model is 81.92% for K = 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best k is 5 with the prediction accuracy of 86.44% ,because the kNN classifier determines the class of a data point by majority voting principle. When k is set to 5, the classes of 5 closest points are checked. Prediction is done according to the majority class. Similarly, kNN regression takes the mean value of 5 closest points which gives the best match for the given query point.\n",
        "\n",
        "On the other hand when k=1  we estimate our probability based on a single sample:  closest neighbor. This is very sensitive to all sort of distortions like noise, outliers, mislabelling of data.\n",
        "\n",
        "Lower k Values lead to overfitting and higher k values lead to underfitting, hence we should select an optimal k with mid value. Croos validation might be one of the technique which we might use for better selection of k."
      ],
      "metadata": {
        "id": "QK_3BeveSey-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4 - Weighted k-NN \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-FMED-C_RZzq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class to implement KNN"
      ],
      "metadata": {
        "id": "CFGaXyl-Af76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightedKNN:\n",
        "\n",
        "    def __init__(self, k):\n",
        "\n",
        "        \"\"\"\n",
        "        Let k equal the assumed number of classifications.\n",
        "\n",
        "        \"\"\"\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        \"\"\"\n",
        "        Method to fit training data to the model. We also assert that \n",
        "        then length of the training data and targets are the same.\n",
        "        \"\"\"\n",
        "        assert len(X) == len(y)\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        return self\n",
        "\n",
        "    def _distance(self, data1, data2):\n",
        "\n",
        "        \"\"\"\n",
        "        Finding the eucledian distance\n",
        "        \"\"\"\n",
        "        return np.sqrt(sum((data1 - data2)**2))\n",
        "        \n",
        "\n",
        "    def _compute_weights(self, distances):\n",
        "\n",
        "       \"\"\"\n",
        "       Computing the weights using inverse distance\n",
        "       if the distance = 0, assign 1\n",
        "       \"\"\"\n",
        "       matches = [(1, y) for d, y in distances if d == 0]\n",
        "       return matches if matches else [(1/np.square(d), y) for d, y in distances]\n",
        "  \n",
        "    def _predict_weight(self, test):\n",
        "\n",
        "        \"\"\"\n",
        "        Method to predict based by adding of weights into account\n",
        "\n",
        "        \"\"\"\n",
        "        distances = sorted((self._distance(x, test), y) for x, y in zip(self.X, self.y))\n",
        "        weights = self._compute_weights(distances[:self.k])\n",
        "        weights_by_class = defaultdict(list)\n",
        "        for d, c in weights:\n",
        "            weights_by_class[c].append(d)\n",
        "        return max((sum(val), key) for key, val in weights_by_class.items())[1]\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        return [self._predict_weight(x) for x in X]\n",
        "\n",
        "    def score(self, X, y):\n",
        "\n",
        "        \"\"\"\n",
        "        Method takes the X_test and y_test, runs the data through the predict method.\n",
        "        The number of successful guesses are summed and compared to the total number in the test data.\n",
        "        \"\"\"\n",
        "        return sum(1 for pred, true in zip(self.predict(X), y) if pred == true) / len(y)"
      ],
      "metadata": {
        "id": "FwtZr4HURgfI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate the weighted KNN model with K\n",
        "testing_neighbors_wknn = WeightedKNN(k=5)\n",
        "\n",
        "# Fit the model to the training data.\n",
        "testing_neighbors_wknn.fit(X_train.to_numpy(), flatten(Y_train.values.tolist()))\n",
        "\n",
        "# Run predictions using the test sample data.\n",
        "prediction = testing_neighbors_wknn.predict(X_test.to_numpy())\n",
        "\n",
        "# Prediction accuracy.\n",
        "pred_acc_wknn = testing_neighbors_wknn.score(X_test.to_numpy(),flatten(Y_test.values.tolist()))\n",
        "\n",
        "data = {'y_Actual':   flatten(Y_test.values.tolist()),\n",
        "       'y_Predicted': prediction \n",
        "       }\n",
        "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], \n",
        "                               rownames=['Actual'], colnames=['Predicted'], \n",
        "                               margins = True)\n",
        "\n",
        "print('The accuracy of the model is :', round(pred_acc_wknn*100,2),'%')\n",
        "print(\"***************************\")\n",
        "print(\"'Confusion Matrix'\")\n",
        "print(\"***************************\")\n",
        "print(confusion_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avzMkYxE4VSH",
        "outputId": "1e8f7c1e-5e88-4bc1-9b83-539329f38a73"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the model is : 84.18 %\n",
            "***************************\n",
            "'Confusion Matrix'\n",
            "***************************\n",
            "Predicted  0.0  1.0  All\n",
            "Actual                  \n",
            "0.0         92   12  104\n",
            "1.0         16   57   73\n",
            "All        108   69  177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K=[1, 3, 5, 7, 9, 11]\n",
        "\n",
        "for i in K :\n",
        "  #Instantiate the weighted KNN model with K\n",
        "  testing_neighbors_wknn = WeightedKNN(k=i)\n",
        "\n",
        "  # Fit the model to the training data.\n",
        "  testing_neighbors_wknn.fit(X_train.to_numpy(), flatten(Y_train.values.tolist()))\n",
        "\n",
        "  # Run predictions using the test sample data.\n",
        "  prediction = testing_neighbors_wknn.predict(X_test.to_numpy())\n",
        "\n",
        "  # Prediction accuracy.\n",
        "  pred_acc_wknn = testing_neighbors_wknn.score(X_test.to_numpy(),flatten(Y_test.to_numpy()))\n",
        "\n",
        "  print(\"The accuracy of the model is %.2f%s for K %d\" % (round(pred_acc_wknn*100,2),'%', i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0alAhfM6PFs",
        "outputId": "9ea02adb-80de-49a5-ba7a-b6eefbfeb15a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the model is 81.92% for K 1\n",
            "The accuracy of the model is 83.05% for K 3\n",
            "The accuracy of the model is 84.18% for K 5\n",
            "The accuracy of the model is 84.18% for K 7\n",
            "The accuracy of the model is 84.18% for K 9\n",
            "The accuracy of the model is 84.75% for K 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the obtained results in Normal k-NN and weighted k-NN,we can conclude that, for the datasets, both the majority voting kNN and the inverse distance squared-weighted knearest neighbor rule.In both cases the\n",
        "differences are not overwhelming.\n",
        "\n",
        "But the Weighted k-NN does not outperform for the given data set. It might give better results for large data sets."
      ],
      "metadata": {
        "id": "RRAXH_EDRlm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REFERENCES**"
      ],
      "metadata": {
        "id": "K_DLUG2OegLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the link which I have used as an reference to build my k-NN code.\n",
        "\n",
        "I have used the same code of my normal k-NN to create the weighted k-NN by adding methods.\n",
        "\n",
        "http://robdbennett.com/2020-09-25-Cluster_From_Scratch/"
      ],
      "metadata": {
        "id": "9VvtxjACerEf"
      }
    }
  ]
}